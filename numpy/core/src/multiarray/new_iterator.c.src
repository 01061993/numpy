#define PY_SSIZE_T_CLEAN
#include "Python.h"
#include "structmember.h"

#define _MULTIARRAYMODULE
#include <numpy/ndarrayobject.h>

#include "new_iterator.h"

/* Adjust ptr to be the next 16-byte aligned position after adding 'amount' */
#define NPY_INC_BUFFERPTR(ptr, amount) \
            ptr = ((char*)(((npy_intp)(ptr)+(amount)+0xf)&(-0x10)))

/* Internal iterator flags */

/* The perm is the identity */
#define NPY_ITER_FLAGS_IDENTPERM   0x001
/* The perm has negative entries (indicating flipped axes) */
#define NPY_ITER_FLAGS_NEGPERM     0x002
/* The iterator is tracking an index */
#define NPY_ITER_FLAGS_HASINDEX    0x004
/* The iterator is tracking coordinates */
#define NPY_ITER_FLAGS_HASCOORDS   0x008
/* The iteration order was forced on construction */
#define NPY_ITER_FLAGS_FORCEDORDER 0x010
/* The inner loop is handled outside the iterator */
#define NPY_ITER_FLAGS_NOINNER     0x020

/* Internal flag, for the type of operands */
#define NPY_ITER_OP_ARRAY         0
#define NPY_ITER_OP_ARRAY_SCALAR  1
#define NPY_ITER_OP_NULL          2

/*
 * The data layout of the iterator is fully specified by
 * a triple (itflags, ndim, niter).  These three variables
 * are expected to exist in all functions calling these macros,
 * either as true variables initialized to the correct values
 * from the iterator, or as constants in the case of specialized
 * functions such as the various iternext functions.
 *
 * If this layout changes, the function 'npyiter_shrink_ndim'
 * needs to be changed as well.
 */

/* Byte offsets of the iterator members */
#define NIT_ITERSIZE_OFFSET() \
        (8)
#define NIT_PERM_OFFSET() \
        (NIT_ITERSIZE_OFFSET() + \
         (NPY_SIZEOF_INTP))
#define NIT_DTYPES_OFFSET(itflags, ndim, niter) \
        (NIT_PERM_OFFSET() + \
         (NPY_SIZEOF_INTP)*(ndim))
#define NIT_ITEMSIZES_OFFSET(itflags, ndim, niter) \
        (NIT_DTYPES_OFFSET(itflags, ndim, niter) + \
         (NPY_SIZEOF_INTP)*(niter))
#define NIT_RESETDATAPTR_OFFSET(itflags, ndim, niter) \
        (NIT_ITEMSIZES_OFFSET(itflags, ndim, niter) + \
         (NPY_SIZEOF_INTP)*(niter))
#define NIT_OBJECTS_OFFSET(itflags, ndim, niter) \
        (NIT_RESETDATAPTR_OFFSET(itflags, ndim, niter) + \
         (NPY_SIZEOF_INTP)*(niter+1))
#define NIT_AXISDATA_OFFSET(itflags, ndim, niter) \
        (NIT_OBJECTS_OFFSET(itflags, ndim, niter) + \
         (NPY_SIZEOF_INTP)*(niter))

/* Internal-only ITERATOR DATA MEMBER ACCESS */
#define NIT_ITFLAGS(iter) \
        (*((npy_uint32*)(iter)))
#define NIT_NDIM(iter) \
        (*((npy_uint16*)(iter) + 2))
#define NIT_NITER(iter) \
        (*((npy_uint16*)(iter) + 3))
#define NIT_ITERSIZE(iter) (*((npy_intp*)( \
        (char*)(iter) + NIT_ITERSIZE_OFFSET())))
#define NIT_PERM(iter)  ((npy_intp*)( \
        (char*)(iter) + NIT_PERM_OFFSET()))
#define NIT_DTYPES(iter) ((PyArray_Descr**)( \
        (char*)(iter) + NIT_DTYPES_OFFSET(itflags, ndim, niter)))
#define NIT_ITEMSIZES(iter) ((npy_intp*)( \
        (char*)(iter) + NIT_ITEMSIZES_OFFSET(itflags, ndim, niter)))
#define NIT_RESETDATAPTR(iter) ((char**)( \
        (char*)(iter) + NIT_RESETDATAPTR_OFFSET(itflags, ndim, niter)))
#define NIT_OBJECTS(iter) ((PyObject**)( \
        (char*)(iter) + NIT_OBJECTS_OFFSET(itflags, ndim, niter)))
#define NIT_AXISDATA(iter) \
        ((char*)(iter) + NIT_AXISDATA_OFFSET(itflags, ndim, niter))

/* Internal-only AXISDATA MEMBER ACCESS. */
#define NAD_SHAPE(axisdata) (*((npy_intp*)(axisdata)))
#define NAD_COORD(axisdata) (*((npy_intp*)(axisdata) + 1))
#define NAD_STRIDES(axisdata) ((npy_intp*)(axisdata) + 2)
#define NAD_PTRS(axisdata) \
        ((char**)(axisdata) + 2 + NAD_NSTRIDES())
#define NAD_NSTRIDES() \
        ((niter) + ((itflags&NPY_ITER_FLAGS_HASINDEX) ? 1 : 0))

/* Size of one AXISDATA struct within the iterator */
#define NIT_SIZEOF_AXISDATA(itflags, ndim, niter) (( \
        /* intp shape */ \
        1 + \
        /* intp coord */ \
        1 + \
        /* intp stride[niter] AND char* ptr[niter] */ \
        2*(niter) + \
        /* intp indexstride AND intp index (when index is provided) */ \
        ((itflags&NPY_ITER_FLAGS_HASINDEX) ? 2 : 0) \
        )*NPY_SIZEOF_INTP ) \

/* Size of the whole iterator */
#define NIT_SIZEOF_ITERATOR(itflags, ndim, niter) ( \
        NIT_AXISDATA_OFFSET(itflags, ndim, niter) + \
        NIT_SIZEOF_AXISDATA(itflags, ndim, niter)*(ndim))

/* Internal helper functions */
static int
pyiter_check_global_flags(npy_uint32 flags, npy_uint32* itflags);
static int
pyiter_prepare_operand(PyObject** op, PyArray_Descr** op_dtype,
                       int* op_type, npy_intp* op_ndim, npy_intp* ndim);
static int
npyiter_check_flags_readwrite(PyObject* op, PyArray_Descr* op_dtype,
                              int op_type, npy_uint32 flags);
static int
npyiter_fill_axisdata(PyArray_NpyIter *iter, PyObject **op,
                      npy_intp *op_ndim, char **op_dataptr,
                      npy_intp **op_axes);
static void
npyiter_compute_index_strides(PyArray_NpyIter *iter, npy_uint32 flags);
static void
npyiter_apply_forced_iteration_order(npy_uint32 flags, PyArray_NpyIter *iter);

static void
npyiter_flip_negative_strides(PyArray_NpyIter *iter);
static void
npyiter_reverse_axis_ordering(PyArray_NpyIter *iter);
static void 
npyiter_find_best_axis_ordering(PyArray_NpyIter *iter);
static void 
npyiter_coalesce_axes(PyArray_NpyIter *iter);
static void
npyiter_shrink_ndim(PyArray_NpyIter *iter, npy_intp new_ndim);

/* The constructor for an iterator over multiple objects */
PyArray_NpyIter*
NpyIter_MultiNew(npy_intp niter, PyObject **op_in, npy_uint32 flags,
                 npy_uint32 *op_flags, PyArray_Descr **op_request_dtypes,
                 int min_ndim, int max_ndim,
                 npy_intp oa_ndim, npy_intp **op_axes)
{
    npy_uint32 itflags = NPY_ITER_FLAGS_IDENTPERM;
    npy_intp idim, ndim = 1;
    npy_intp iiter;

    /* The iterator being constructed */
    PyArray_NpyIter *iter;

    /* For tracking buffer space at the end of the iterator memory */
    npy_intp bufferspace = 0;
    char *bufferptr = 0;

    /* Per-operand values */
    PyObject *op[NPY_MAXARGS];
    PyArray_Descr *op_dtype[NPY_MAXARGS];
    int op_type[NPY_MAXARGS];
    npy_intp op_ndim[NPY_MAXARGS];
    char **op_dataptr;

    npy_intp *perm;
    char axes_dupcheck[NPY_MAXDIMS];

    if (niter > NPY_MAXARGS) {
        PyErr_Format(PyExc_ValueError,
            "Cannot construct an iterator with more than %d operands "
            "(%d were requested)", (int)NPY_MAXARGS, (int)niter);
        return NULL;
    }

    /* Error check 'oa_ndim' and 'op_axes', which must be used together */
    if (oa_ndim == 0 && op_axes != NULL) {
        PyErr_Format(PyExc_ValueError,
                "If 'op_axes' is not NULL in the iterator constructor, "
                "'oa_ndim' must be greater than zero");
        return NULL;
    }
    else if (oa_ndim > 0) {
        if (oa_ndim > NPY_MAXDIMS) {
            PyErr_Format(PyExc_ValueError,
                "Cannot construct an iterator with more than %d dimensions "
                "(%d were requested for op_axes)",
                (int)NPY_MAXDIMS, (int)oa_ndim);
            return NULL;
        }
        else if (op_axes == NULL) {
            PyErr_Format(PyExc_ValueError,
                    "If 'oa_ndim' is greater than zero in the iterator "
                    "constructor, then op_axes cannot be NULL");
            return NULL;
        }

        /* Check that there are no duplicates in op_axes */
        for (iiter = 0; iiter < niter; ++iiter) {
            npy_intp *axes = op_axes[iiter];
            if (axes != NULL) {
                memset(axes_dupcheck, 0, oa_ndim);
                for (idim = 0; idim < oa_ndim; ++idim) {
                    npy_intp i = axes[idim];
                    if (i >= 0) {
                        if (i >= NPY_MAXDIMS ||
                                axes_dupcheck[i] == 1) {
                            PyErr_Format(PyExc_ValueError,
                                    "The 'op_axes' provided to the iterator "
                                    "constructor contained duplicate "
                                    "or invalid values");
                            return NULL;
                        }
                        else {
                            axes_dupcheck[i] = 1;
                        }
                    }
                }
            }
        }
    }

    /* Checks the flags (C|F)_ORDER_INDEX, COORDS, and NO_INNER_ITERATION */
    if (!pyiter_check_global_flags(flags, &itflags)) {
        return NULL;
    }

    /* Prepare all the operands */
    for (iiter = 0; iiter < niter; ++iiter) {
        /*
         * Make a copy of the input operands so we can substitute
         * new values in place when necessary without affecting
         * the caller's array.
         */
        op[iiter] = op_in[iiter];
        Py_XINCREF(op[iiter]);

       /*
        * Prepare the operand.  This eats the op[iiter] reference
        * on an error, and gives an op_dtype[iiter] reference
        * on success.
        */
        if (!pyiter_prepare_operand(&op[iiter], &op_dtype[iiter],
                                &op_type[iiter], &op_ndim[iiter], &ndim)) {
            npy_intp i;

            for (i = 0; i < iiter; ++i) {
                Py_XDECREF(op[i]);
                Py_XDECREF(op_dtype[i]);
            }
            return NULL;
        }

        /* Check the readonly/writeonly flags against the operand */
        if (!npyiter_check_flags_readwrite(op[iiter], op_dtype[iiter],
                                        op_type[iiter], op_flags[iiter])) {
            npy_intp i;

            for (i = 0; i <= iiter; ++i) {
                Py_XDECREF(op[i]);
                Py_XDECREF(op_dtype[i]);
            }
            return NULL;
        }
    }


    /* For now, disallow any NULL operands */
    for (iiter = 0; iiter < niter; ++iiter) {
        if (op_type[iiter] == NPY_ITER_OP_NULL) {
            npy_intp i;

            for (i = 0; i < niter; ++i) {
                Py_XDECREF(op[i]);
                Py_XDECREF(op_dtype[i]);
            }
            PyErr_SetString(PyExc_ValueError,
                    "Iterator input value cannot be NULL");
            return NULL;
        }
    }

    /*
     * For array scalars, the memory may get put into a temporary
     * buffer at the end of the iterator.  16 is added so it can be
     * 16-byte aligned.
     */
    for (iiter = 0; iiter < niter; ++iiter) {
        if (op_type[iiter] == NPY_ITER_OP_ARRAY_SCALAR &&
                    !PyTypeNum_ISEXTENDED(op_dtype[iiter]->type_num)) {
            bufferspace += op_dtype[iiter]->elsize + 16;
        }
    }

    /* If 'op_axes' is being used, force 'ndim' */
    if (oa_ndim > 0) {
        ndim = oa_ndim;
    }

    /* Make sure the number of dimensions matches the requirements */
    if ((min_ndim >= 0 && ndim < min_ndim) ||
            (max_ndim >= 0 && ndim > max_ndim)) {
        npy_intp i;

        PyErr_Format(PyExc_ValueError,
                "Requested an iterator with %d <= ndim <= %d, "
                "but input ndim is %d",
                min_ndim, max_ndim, (int)ndim);
        for (i = 0; i < niter; ++i) {
            Py_XDECREF(op[i]);
            Py_XDECREF(op_dtype[i]);
        }
        return NULL;
    }

    /* Confirm the data types of the array */
    if (op_request_dtypes != NULL) {
        for (iiter = 0; iiter < niter; ++iiter) {
            if (op_request_dtypes[iiter] != NULL) {
                if (!PyObject_TypeCheck(op_request_dtypes[iiter],
                                                &PyArrayDescr_Type)) {
                    PyErr_SetString(PyExc_ValueError,
                            "Iterator requested dtypes must be "
                            "array descrs.");
                    npy_intp i;

                    for (i = 0; i < niter; ++i) {
                        Py_XDECREF(op[i]);
                        Py_XDECREF(op_dtype[i]);
                    }
                    return NULL;
                }

                if (!PyArray_EquivTypes(op_request_dtypes[iiter],
                                            op_dtype[iiter])) {
                    npy_intp i;

                    PyErr_SetString(PyExc_ValueError,
                            "Iterator doesn't support automatic dtype "
                            "conversions yet");
                    for (i = 0; i < niter; ++i) {
                        Py_XDECREF(op[i]);
                        Py_XDECREF(op_dtype[i]);
                    }
                    return NULL;
                }
            }
        }
    }

    /* Allocate memory for the iterator */
    if (bufferspace > 0) {
        npy_intp itsize = NIT_SIZEOF_ITERATOR(itflags, ndim, niter);
        iter = (PyArray_NpyIter*)
                    PyArray_malloc(itsize + bufferspace);
        /* Initialize the buffer pointer to just after the iterator memory */
        bufferptr = (char*)iter;
        NPY_INC_BUFFERPTR(bufferptr, itsize);
    }
    else {
        iter = (PyArray_NpyIter*)
                    PyArray_malloc(NIT_SIZEOF_ITERATOR(itflags, ndim, niter));
    }

    /* Fill in the base data */
    NIT_ITFLAGS(iter) = itflags;
    NIT_NDIM(iter) = ndim;
    NIT_NITER(iter) = niter;
    NIT_ITERSIZE(iter) = 1;
    /* The iterator takes over ownership of the function's 'op_dtype'
     * and 'op' references */
    op_dataptr = NIT_RESETDATAPTR(iter);
    for (iiter = 0; iiter < niter; ++iiter) {
        NIT_DTYPES(iter)[iiter] = op_dtype[iiter];
        NIT_ITEMSIZES(iter)[iiter] = op_dtype[iiter]->elsize;
        NIT_OBJECTS(iter)[iiter] = op[iiter];

        /* Get the data pointer for this operand */
        switch (op_type[iiter]) {
            case NPY_ITER_OP_ARRAY:
                op_dataptr[iiter] = PyArray_DATA(op[iiter]);
                break;
            case NPY_ITER_OP_ARRAY_SCALAR:
                /*
                 * If ISEXTENDED is true (a flexible type), 
                 * ScalarAsCtype fills in a pointer to the data, otherwise
                 * it copies the data itself.
                 */
                if (PyTypeNum_ISEXTENDED(op_dtype[iiter]->type_num)) {
                    PyArray_ScalarAsCtype(op[iiter], &op_dataptr[iiter]);
                }
                else {
                    PyArray_ScalarAsCtype(op[iiter], bufferptr);
                    op_dataptr[iiter] = bufferptr;
                    NPY_INC_BUFFERPTR(bufferptr, op_dtype[iiter]->elsize);
                }
                break;
        }
    }
    /* Set resetindex to zero as well (it's just after the resetdataptr) */
    op_dataptr[niter] = 0;

    /* Fill in the AXISDATA arrays and set the ITERSIZE field */
    if (!npyiter_fill_axisdata(iter, op, op_ndim, op_dataptr, op_axes)) {
        npy_intp i;

        for (i = 0; i < niter; ++i) {
            Py_XDECREF(op[i]);
            Py_XDECREF(op_dtype[i]);
        }
        PyArray_free(iter);
        return NULL;
    }

    /*
     * If an index was requested, compute the strides for it.
     * Note that we must do this before changing the order of the
     * axes
     */
    npyiter_compute_index_strides(iter, flags);

    /* Initialize the perm to the identity */
    perm = NIT_PERM(iter);
    for(idim = 0; idim < ndim; ++idim) {
        perm[idim] = idim;
    }

    /*
     * If there's only one element to iterate, there's no need
     * to do any further iterator manipulation.
     */
    if (NIT_ITERSIZE(iter) == 1) {
        return iter;
    }
 
    /*
     * If an iteration order is being forced, apply it.
     */
    npyiter_apply_forced_iteration_order(flags, iter);
    itflags = NIT_ITFLAGS(iter);

    /*
     * If the ordering was not forced, reorder the axes
     * and flip negative strides to find the best one.
     */
    if (!(itflags&NPY_ITER_FLAGS_FORCEDORDER)) {
        if (ndim > 1) {
            npyiter_find_best_axis_ordering(iter);
        }
        npyiter_flip_negative_strides(iter);
        itflags = NIT_ITFLAGS(iter);
    }

    /*
     * Finally, if coords weren't requested,
     * it may be possible to coalesce some axes together.
     */
    if (!(itflags&NPY_ITER_FLAGS_HASCOORDS)) {
        npyiter_coalesce_axes(iter);
        itflags = NIT_ITFLAGS(iter);
        ndim = NIT_NDIM(iter);
    }

    /* Now that the axes are finished, adjust ITERSIZE if necessary */
    if (itflags&NPY_ITER_FLAGS_NOINNER) {
        char *axisdata = NIT_AXISDATA(iter);
        NIT_ITERSIZE(iter) /= NAD_SHAPE(axisdata);
    }

    return iter;
}

/* The constructor for an iterator over one object */
PyArray_NpyIter*
NpyIter_New(PyObject* op, npy_uint32 flags, PyArray_Descr* dtype,
                  int min_ndim, int max_ndim,
                  npy_intp a_ndim, npy_intp *axes)
{
    /* Split the flags into separate global and op flags */
    npy_uint32 op_flags = flags&NPY_ITER_PER_OP_FLAGS;
    flags &= NPY_ITER_GLOBAL_FLAGS;

    if (a_ndim > 0) {
        return NpyIter_MultiNew(1, &op, flags, &op_flags, &dtype,
                                min_ndim, max_ndim, a_ndim, &axes);
    }
    else {
        return NpyIter_MultiNew(1, &op, flags, &op_flags, &dtype,
                                min_ndim, max_ndim, 0, NULL);
    }
}

int NpyIter_Deallocate(PyArray_NpyIter *iter)
{
    /*npy_uint32 itflags = NIT_ITFLAGS(iter);*/
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp iiter, niter = NIT_NITER(iter);

    PyArray_Descr **dtype = NIT_DTYPES(iter);
    PyObject **object = NIT_OBJECTS(iter);

    /* Deallocate all the dtypes and objects that were iterated */
    for(iiter = 0; iiter < niter; ++iiter, ++dtype, ++object) {
        Py_XDECREF(*dtype);
        Py_XDECREF(*object);
    }

    /* Deallocate the iterator memory */
    PyArray_free(iter);

    return NPY_SUCCEED;
}

/* Resets the iterator to its initial state */
void NpyIter_Reset(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char **resetdataptr;
    char *axisdata;
    npy_intp sizeof_axisdata;
    npy_intp istrides, nstrides;

    resetdataptr = NIT_RESETDATAPTR(iter);
    axisdata = NIT_AXISDATA(iter);
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
    nstrides = NAD_NSTRIDES();
    
    for (idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
        char **ptrs;
        NAD_COORD(axisdata) = 0;
        ptrs = NAD_PTRS(axisdata);
        for (istrides = 0; istrides < nstrides; ++istrides) {
            ptrs[istrides] = resetdataptr[istrides];
        }
    }
}

/*
 * Sets the iterator to the specified coordinates, which must have the
 * correct number of entries for 'ndim'.  It is only valid
 * when NPY_ITER_COORDS was passed to the constructor.  This operation
 * fails if the coordinates are out of bounds.
 *
 * Returns NPY_SUCCEED on success, NPY_FAIL on failure.
 */
int NpyIter_GotoCoords(PyArray_NpyIter *iter, npy_intp *coords)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char **dataptr;
    char *axisdata;
    npy_intp sizeof_axisdata;
    npy_intp istrides, nstrides;
    npy_intp *perm, perm_coords[NPY_MAXDIMS];

    if (!(itflags&NPY_ITER_FLAGS_HASCOORDS)) {
        PyErr_SetString(PyExc_ValueError,
                "Cannot call GotoCoord on an iterator without "
                "the constructor flag NPY_ITER_COORDS.");
        return NPY_FAIL;
    }

    perm = NIT_PERM(iter);
    dataptr = NIT_RESETDATAPTR(iter);
    axisdata = NIT_AXISDATA(iter);
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);

    /* Permute the input coordinates to match the iterator */
    char *ad = axisdata;
    for (idim = 0; idim < ndim; ++idim, ad += sizeof_axisdata) {
        npy_intp p = perm[idim], i, shape;
        if (p < 0) {
            /* If the perm entry is negative, reverse the coordinate */
            shape = NAD_SHAPE(ad);
            i = shape - coords[ndim+p] - 1;
        }
        else {
            shape = NAD_SHAPE(ad);
            i = coords[ndim-p-1];
        }

        /* Bounds-check this coordinate */
        if (i >= 0 && i < shape) {
            perm_coords[idim] = i;
        }
        else {
            PyErr_SetString(PyExc_IndexError,
                    "Iterator GotoCoord called with out-of-bounds "
                    "coordinates.");
            return NPY_FAIL;
        }
    }

    nstrides = NAD_NSTRIDES();

    /*
     * Set the coordinates, from the slowest-changing to the
     * fastest-changing.  The successive pointers accumulate
     * the offsets, starting from the original data pointers.
     */
    axisdata += (ndim-1)*sizeof_axisdata;
    for (idim = ndim-1; idim >= 0; --idim, axisdata -= sizeof_axisdata) {
        npy_intp i, *strides;
        char **ptrs;

        NAD_COORD(axisdata) = i = perm_coords[idim];
        strides = NAD_STRIDES(axisdata);
        ptrs = NAD_PTRS(axisdata);
        for (istrides = 0; istrides < nstrides; ++istrides) {
            ptrs[istrides] = dataptr[istrides] + i*strides[istrides];
        }

        dataptr = ptrs;
    }

    return NPY_SUCCEED;
}

/* If the iterator is tracking an index, sets the iterator
 * to the specified index.
 *
 * Returns NPY_SUCCEED on success, NPY_FAIL on failure.
 */
int NpyIter_GotoIndex(PyArray_NpyIter *iter, npy_intp index)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char **dataptr;
    char *axisdata;
    npy_intp sizeof_axisdata;
    npy_intp istrides, nstrides;

    if (!(itflags&NPY_ITER_FLAGS_HASINDEX)) {
        PyErr_SetString(PyExc_ValueError,
                "Cannot call GotoIndex on an iterator without "
                "the constructor flag NPY_ITER_(C|F)_ORDER_INDEX.");
        return NPY_FAIL;
    }

    if (index < 0 || index >= NIT_ITERSIZE(iter)) {
        PyErr_SetString(PyExc_IndexError,
                "Iterator GotoIndex called with out-of-bounds "
                "index.");
        return NPY_FAIL;
    }

    dataptr = NIT_RESETDATAPTR(iter);
    axisdata = NIT_AXISDATA(iter);
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
    nstrides = NAD_NSTRIDES();

    /*
     * Set the coordinates, from the slowest-changing to the
     * fastest-changing.  The successive pointers accumulate
     * the offsets, starting from the original data pointers.
     */
    axisdata += (ndim-1)*sizeof_axisdata;
    for (idim = 0; idim < ndim; ++idim, axisdata -= sizeof_axisdata) {
        npy_intp i, shape, iterstride, *strides;
        char **ptrs;

        shape = NAD_SHAPE(axisdata);
        strides = NAD_STRIDES(axisdata);
        ptrs = NAD_PTRS(axisdata);
        iterstride = strides[niter];

        /* Extract the coordinate from the index */
        if (iterstride == 0) {
            i = 0;
        }
        else if (iterstride < 0) {
            i = shape - (index/(-iterstride))%shape - 1;
        }
        else {
            i = (index/iterstride)%shape;
        }

        NAD_COORD(axisdata) = i;

        for (istrides = 0; istrides < nstrides; ++istrides) {
            ptrs[istrides] = dataptr[istrides] + i*strides[istrides];
        }

        dataptr = ptrs;
    }

    return NPY_SUCCEED;
}

/* SPECIALIZED iternext functions */

    /* The combination HASINDEX | NOINNER is excluded in the New functions */
/**begin repeat
 * #const_itflags = 0,
 *                  NPY_ITER_FLAGS_HASINDEX,
 *                  NPY_ITER_FLAGS_NOINNER#
 * #tag_itflags = 0, IND, NOINN#
 */
/**begin repeat1
 * #const_ndim = 1, 2, 100#
 * #tag_ndim = 1, 2, ANY#
 */
/**begin repeat2
 * #const_niter = 1, 2, 100#
 * #tag_niter = 1, 2, ANY#
 */

/* Specialized iternext (@const_itflags@,@const_ndim@,@const_niter@) */
NPY_NO_EXPORT int
npyiter_iternext_itflags@tag_itflags@_dims@tag_ndim@_iters@tag_niter@(
                                                      PyArray_NpyIter *iter)
{
    const npy_uint32 itflags = @const_itflags@;
#if @const_ndim@ < 100
    const npy_intp ndim = @const_ndim@;
#else
    npy_intp idim, ndim = NIT_NDIM(iter);
#endif
#if @const_ndim@ < 100
    const npy_intp niter = @const_niter@;
#else
    npy_intp niter = NIT_NITER(iter);
#endif

    npy_intp istrides, nstrides, sizeof_axisdata;
#if @const_ndim@ > 0
    char* axisdata0;
#endif
#if @const_ndim@ > 1
    char* axisdata1;
#endif
#if @const_ndim@ > 2
    char* axisdata2;
#endif

    nstrides = NAD_NSTRIDES();
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);

    axisdata0 = NIT_AXISDATA(iter);
#  if !(@const_itflags@&NPY_ITER_FLAGS_NOINNER)
    /* Increment coordinate 0 */
    NAD_COORD(axisdata0)++;
    /* Increment pointer 0 */
    for (istrides = 0; istrides < nstrides; ++istrides) {
        NAD_PTRS(axisdata0)[istrides] += NAD_STRIDES(axisdata0)[istrides];
    }
#  endif

#if @const_ndim@ == 1

#  if !(@const_itflags@&NPY_ITER_FLAGS_NOINNER)
    /* Finished when the coordinate equals the shape */
    return NAD_COORD(axisdata0) < NAD_SHAPE(axisdata0);
#  else
    /* Get rid of unused variable warning */
    istrides = 0;

    return 0;
#  endif

#else

#  if !(@const_itflags@&NPY_ITER_FLAGS_NOINNER)
    if (NAD_COORD(axisdata0) < NAD_SHAPE(axisdata0)) {
        return 1;
    }
#  endif

    axisdata1 = axisdata0 + sizeof_axisdata;
    /* Increment coordinate 1 */
    NAD_COORD(axisdata1)++;
    /* Increment pointer 1 */
    for (istrides = 0; istrides < nstrides; ++istrides) {
        NAD_PTRS(axisdata1)[istrides] += NAD_STRIDES(axisdata1)[istrides];
    }

    if (NAD_COORD(axisdata1) < NAD_SHAPE(axisdata1)) {
        /* Reset the 1st coordinate to 0 */
        NAD_COORD(axisdata0) = 0;
        /* Reset the 1st pointer to the value of the 2nd */
        for (istrides = 0; istrides < nstrides; ++istrides) {
            NAD_PTRS(axisdata0)[istrides] = NAD_PTRS(axisdata1)[istrides];
        }
        return 1;
    }

# if @const_ndim@ == 2
    return 0;
# else
    
    axisdata2 = axisdata1 + sizeof_axisdata;
    /* Increment coordinate 2 */
    NAD_COORD(axisdata2)++;
    /* Increment pointer 2 */
    for (istrides = 0; istrides < nstrides; ++istrides) {
        NAD_PTRS(axisdata2)[istrides] += NAD_STRIDES(axisdata2)[istrides];
    }

    if (NAD_COORD(axisdata2) < NAD_SHAPE(axisdata2)) {
        /* Reset the 1st and 2nd coordinates to 0 */
        NAD_COORD(axisdata0) = 0;
        NAD_COORD(axisdata1) = 0;
        /* Reset the 1st and 2nd pointers to the value of the 3nd */
        for (istrides = 0; istrides < nstrides; ++istrides) {
            NAD_PTRS(axisdata0)[istrides] = NAD_PTRS(axisdata2)[istrides];
            NAD_PTRS(axisdata1)[istrides] = NAD_PTRS(axisdata2)[istrides];
        }
        return 1;
    }

    for (idim = 3; idim < ndim; ++idim) {
        axisdata2 += sizeof_axisdata;
        /* Increment the coordinate */
        NAD_COORD(axisdata2)++;
        /* Increment the pointer */
        for (istrides = 0; istrides < nstrides; ++istrides) {
            NAD_PTRS(axisdata2)[istrides] += NAD_STRIDES(axisdata2)[istrides];
        }


        if (NAD_COORD(axisdata2) < NAD_SHAPE(axisdata2)) {
            /* Reset the coordinates and pointers of all previous axisdatas */
            axisdata1 = axisdata2;
            do {
                axisdata1 -= sizeof_axisdata;
                /* Reset the coordinate to 0 */
                NAD_COORD(axisdata1) = 0;
                /* Reset the pointer to the updated value */
                for (istrides = 0; istrides < nstrides; ++istrides) {
                    NAD_PTRS(axisdata1)[istrides] =
                                        NAD_PTRS(axisdata2)[istrides];
                }
            } while (axisdata1 != axisdata0);

            return 1;
        }
    }

    return 0;

# endif /* ndim != 2 */
    
#endif /* ndim != 1 */
}

/**end repeat2**/
/**end repeat1**/
/**end repeat**/

/* Specialization of iternext for when the iteration size is 1 */
NPY_NO_EXPORT int
npyiter_iternext_sizeone(PyArray_NpyIter *iter)
{
    return 0;
}

/* Returns a specialized iternext function */
NpyIter_IterNext_Fn NpyIter_GetIterNext(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    /*
     * When there is just one element being iterated,
     * the iternext function is very simple
     */
    if (NIT_ITERSIZE(iter) == 1) {
        return &npyiter_iternext_sizeone;
    }

    /*
     * Ignore all the flags that don't affect the iterator memory
     * layout or the iternext function.  Currently only HASINDEX
     * and NOINNER affect them.
     */
    itflags &= (NPY_ITER_FLAGS_HASINDEX|NPY_ITER_FLAGS_NOINNER);

    /* Switch statements let the compiler optimize this most effectively */
    switch (itflags) {
    /* The combination HASINDEX | NOINNER is excluded in the New functions */
/**begin repeat
 * #const_itflags = 0,
 *                  NPY_ITER_FLAGS_HASINDEX,
 *                  NPY_ITER_FLAGS_NOINNER#
 * #tag_itflags = 0, IND, NOINN#
 */
        case @const_itflags@:
            switch (ndim) {
/**begin repeat1
 * #const_ndim = 1, 2#
 * #tag_ndim = 1, 2#
 */
                case @const_ndim@:
                    switch (niter) {
/**begin repeat2
 * #const_niter = 1, 2#
 * #tag_niter = 1, 2#
 */
                        case @const_niter@:
                            return &npyiter_iternext_itflags@tag_itflags@_dims@tag_ndim@_iters@tag_niter@;
/**end repeat2**/
                        /* Not specialized on niter */
                        default:
                            return &npyiter_iternext_itflags@tag_itflags@_dims@tag_ndim@_itersANY;
                    }
/**end repeat1**/
                /* Not specialized on ndim */
                default:
                    switch (niter) {
/**begin repeat1
 * #const_niter = 1, 2#
 * #tag_niter = 1, 2#
 */
                        case @const_niter@:
                            return &npyiter_iternext_itflags@tag_itflags@_dimsANY_iters@tag_niter@;
/**end repeat1**/
                        /* Not specialized on niter */
                        default:
                            return &npyiter_iternext_itflags@tag_itflags@_dimsANY_itersANY;
                    }
            }
/**end repeat**/
    }
    /* The switch above should have caught all the possibilities. */
    PyErr_Format(PyExc_ValueError,
            "GetIterNext internal iterator error - unexpected "
            "itflags/ndim/niter combination (%04x/%d/%d)",
            (int)itflags, (int)ndim, (int)niter);
    return NULL;
}


/* SPECIALIZED getcoord functions */

/**begin repeat
 * #const_itflags = 0,
 *    NPY_ITER_FLAGS_HASINDEX,
 *    NPY_ITER_FLAGS_IDENTPERM,
 *    NPY_ITER_FLAGS_HASINDEX|NPY_ITER_FLAGS_IDENTPERM,
 *    NPY_ITER_FLAGS_NEGPERM,
 *    NPY_ITER_FLAGS_HASINDEX|NPY_ITER_FLAGS_NEGPERM#
 * #tag_itflags = 0, IND, IDP, INDuIDP, NEGP, INDuNEGP#
 */
NPY_NO_EXPORT void
npyiter_getcoord_itflags@tag_itflags@(PyArray_NpyIter *iter, npy_intp *outcoord)
{
    const npy_uint32 itflags = @const_itflags@;
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    npy_intp idim, sizeof_axisdata;
    char* axisdata;
#if !((@const_itflags@)&NPY_ITER_FLAGS_IDENTPERM)
    npy_intp* perm = NIT_PERM(iter);
#endif

    axisdata = NIT_AXISDATA(iter);
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
#if ((@const_itflags@)&NPY_ITER_FLAGS_IDENTPERM)
    outcoord += ndim-1;
    for(idim = 0; idim < ndim; ++idim, --outcoord,
                                    axisdata += sizeof_axisdata) {
        *outcoord = NAD_COORD(axisdata);
    }
#elif !((@const_itflags@)&NPY_ITER_FLAGS_NEGPERM)
    for(idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
        npy_intp p = perm[idim];
        outcoord[ndim-p-1] = NAD_COORD(axisdata);
    }
#else
    for(idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
        npy_intp p = perm[idim];
        if (p < 0) {
            /* If the perm entry is negative, reverse the coordinate */
            outcoord[ndim+p] = NAD_SHAPE(axisdata) - NAD_COORD(axisdata) - 1;
        }
        else {
            outcoord[ndim-p-1] = NAD_COORD(axisdata);
        }
    }
#endif /* not ident perm */
}
/**end repeat**/

/* Returns a specialized getcoord function */
NpyIter_GetCoords_Fn NpyIter_GetGetCoords(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    if (!(itflags&NPY_ITER_FLAGS_HASCOORDS)) {
        PyErr_SetString(PyExc_ValueError,
                "Cannot get a GetCoords function for an iterator "
                "that doesn't track coordinates.");
        return NULL;
    }

    /*
     * Only these flags affect the iterator memory layout or
     * the getcoords behavior. IDENTPERM and NEGPERM are mutually
     * exclusive, so that reduces the number of cases slightly.
     */
    itflags &= (NPY_ITER_FLAGS_HASINDEX |
                NPY_ITER_FLAGS_IDENTPERM |
                NPY_ITER_FLAGS_NEGPERM);
    
    switch (itflags) {
/**begin repeat
 * #const_itflags = 0,
 *    NPY_ITER_FLAGS_HASINDEX,
 *    NPY_ITER_FLAGS_IDENTPERM,
 *    NPY_ITER_FLAGS_HASINDEX|NPY_ITER_FLAGS_IDENTPERM,
 *    NPY_ITER_FLAGS_NEGPERM,
 *    NPY_ITER_FLAGS_HASINDEX|NPY_ITER_FLAGS_NEGPERM#
 * #tag_itflags = 0, IND, IDP, INDuIDP, NEGP, INDuNEGP#
 */
        case @const_itflags@:
            return npyiter_getcoord_itflags@tag_itflags@;
/**end repeat**/
    }
    /* The switch above should have caught all the possibilities. */
    PyErr_Format(PyExc_ValueError,
            "GetGetCoords internal iterator error - unexpected "
            "itflags/ndim/niter combination (%04x/%d/%d)",
            (int)itflags, (int)ndim, (int)niter);
    return NULL;

}

int NpyIter_HasCoords(PyArray_NpyIter *iter)
{
    return (NIT_ITFLAGS(iter)&NPY_ITER_FLAGS_HASCOORDS) != 0;
}

int NpyIter_HasIndex(PyArray_NpyIter *iter)
{
    return (NIT_ITFLAGS(iter)&NPY_ITER_FLAGS_HASINDEX) != 0;
}

npy_intp NpyIter_GetNDim(PyArray_NpyIter *iter)
{
    return NIT_NDIM(iter);
}

npy_intp NpyIter_GetNIter(PyArray_NpyIter *iter)
{
    return NIT_NITER(iter);
}

npy_intp NpyIter_GetIterSize(PyArray_NpyIter *iter)
{
    return NIT_ITERSIZE(iter);
}

char **NpyIter_GetDataPtrArray(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char* axisdata = NIT_AXISDATA(iter);

    return NAD_PTRS(axisdata);
}

PyArray_Descr **NpyIter_GetDescrArray(PyArray_NpyIter *iter)
{
    /*npy_uint32 itflags = NIT_ITFLAGS(iter);*/
    npy_intp ndim = NIT_NDIM(iter);
    /*npy_intp niter = NIT_NITER(iter);*/

    return NIT_DTYPES(iter);
}

npy_intp *NpyIter_GetIndexPtr(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char* axisdata = NIT_AXISDATA(iter);

    if (itflags&NPY_ITER_FLAGS_HASINDEX) {
        /* The index is just after the data pointers */
        return (npy_intp*)NAD_PTRS(axisdata) + niter;
    }
    else {
        return NULL;
    }
}

npy_intp *NpyIter_GetItemSizeArray(PyArray_NpyIter *iter)
{
    /*npy_uint32 itflags = NIT_ITFLAGS(iter);*/
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);
    
    return NIT_ITEMSIZES(iter);
}

npy_intp *NpyIter_GetInnerStrideArray(PyArray_NpyIter *iter)
{
    /*npy_uint32 itflags = NIT_ITFLAGS(iter);*/
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char* axisdata = NIT_AXISDATA(iter);
    return NAD_STRIDES(axisdata);
}

npy_intp* NpyIter_GetInnerLoopSizePtr(PyArray_NpyIter *iter)
{
    /*npy_uint32 itflags = NIT_ITFLAGS(iter);*/
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char* axisdata = NIT_AXISDATA(iter);
    return &NAD_SHAPE(axisdata);
}

/* Checks 'flags' for (C|F)_ORDER_INDEX, COORDS, and NO_INNER_ITERATION,
 * setting the appropriate internal flags in 'itflags'.
 *
 * Returns 1 on success, 0 on error.
 */
static int
pyiter_check_global_flags(npy_uint32 flags, npy_uint32* itflags)
{
    if ((flags&NPY_ITER_PER_OP_FLAGS) != 0) {
        PyErr_SetString(PyExc_ValueError,
                    "A per-operand flag was passed as a global flag "
                    "to the iterator constructor");
        return 0;
    }

    /* Check for an index */
    if (flags&(NPY_ITER_C_ORDER_INDEX | NPY_ITER_F_ORDER_INDEX)) {
        if ((flags&(NPY_ITER_C_ORDER_INDEX | NPY_ITER_F_ORDER_INDEX)) ==
                    (NPY_ITER_C_ORDER_INDEX | NPY_ITER_F_ORDER_INDEX)) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator flags NPY_ITER_C_ORDER_INDEX and "
                    "NPY_ITER_F_ORDER_INDEX cannot both be specified");
            return 0;
        }
        (*itflags) |= NPY_ITER_FLAGS_HASINDEX;
    }
    /* Check if coordinates were requested */
    if (flags&NPY_ITER_COORDS) {
        /*
         * This flag primarily disables dimension manipulations that
         * would produce a different set of coordinates.
         */
        (*itflags) |= NPY_ITER_FLAGS_HASCOORDS;
    }
    /* Check that at most one forced ordering is specified */
    if (flags&(NPY_ITER_FORCE_C_ORDER|
                        NPY_ITER_FORCE_F_ORDER|
                        NPY_ITER_FORCE_ANY_CONTIGUOUS)) {
        if (((flags&NPY_ITER_FORCE_C_ORDER) &&
                            (flags&(NPY_ITER_FORCE_F_ORDER|
                                    NPY_ITER_FORCE_ANY_CONTIGUOUS))) ||
                        ((flags&(NPY_ITER_FORCE_F_ORDER|
                                 NPY_ITER_FORCE_ANY_CONTIGUOUS)) ==
                            (NPY_ITER_FORCE_F_ORDER|
                             NPY_ITER_FORCE_ANY_CONTIGUOUS))) {
            PyErr_SetString(PyExc_ValueError,
                    "Only one of NPY_ITER_FORCE_C_ORDER, "
                    "NPY_ITER_FORCE_F_ORDER, and "
                    "NPY_ITER_FORCE_ANY_CONTIGUOUS may be specified");
            return 0;
        }
    }
    /* Check if the caller wants to handle inner iteration */
    if (flags&NPY_ITER_NO_INNER_ITERATION) {
        if ((*itflags)&NPY_ITER_FLAGS_HASINDEX) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator flags NPY_ITER_(C|F)_ORDER_INDEX and "
                    "NPY_ITER_NO_INNER_ITERATION cannot be used "
                    "together");
            return 0;
        }
        if ((*itflags)&NPY_ITER_FLAGS_HASCOORDS) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator flags NPY_ITER_COORDS and "
                    "NPY_ITER_NO_INNER_ITERATION cannot be used "
                    "together");
            return 0;
        }
        (*itflags) |= NPY_ITER_FLAGS_NOINNER;
    }

    return 1;
}

/*
 * Prepares a a constructor operand.  Assumes a reference to 'op'
 * is owned, and that 'op' may be replaced.  Fills in 'op_dtype',
 * 'op_type' and 'ndim'.
 *
 * Returns 1 on success, 0 on failure.
 */
static int
pyiter_prepare_operand(PyObject** op, PyArray_Descr** op_dtype,
                       int* op_type, npy_intp* op_ndim, npy_intp* ndim)
{
    /* NULL operands may be automatically allocated outputs */
    if (*op == NULL) {
        *op_dtype = NULL;
        *op_type = NPY_ITER_OP_NULL;
        *op_ndim = 0;
        return 1;
    }

    /* If it's a Python number, convert it into an array scalar */
    if (PyArray_IsPythonNumber(*op)) {
        PyObject *new_op = PyArray_ScalarFromObject(*op);
        Py_DECREF(*op);
        if (new_op == NULL) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator input failed to convert to array scalar");
            return 0;
        }
        *op = new_op;
    }

    if (PyArray_Check(*op)) {
        *op_type = NPY_ITER_OP_ARRAY;
        *op_ndim = PyArray_NDIM(*op);
        /* PyArray_DESCR does not give us a reference */
        *op_dtype = PyArray_DESCR(*op);
        if (*op_dtype == NULL) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator input array object has no dtype descr");
            Py_DECREF(*op);
            return 0;
        }
        Py_INCREF(*op_dtype);
    }
    else if(PyArray_CheckScalar(*op)) {
        *op_type = NPY_ITER_OP_ARRAY_SCALAR;
        *op_ndim = 0;
        /*PyArray_DescrFromScalar does give us a reference */
        *op_dtype = PyArray_DescrFromScalar(*op);
        if (*op_dtype == 0) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator input array scalar has no dtype descr");
            Py_DECREF(*op);
            return 0;
        }
        if (PyDataType_FLAGCHK(*op_dtype, NPY_ITEM_HASOBJECT) ||
                    PyDataType_FLAGCHK(*op_dtype, NPY_ITEM_IS_POINTER)) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator input array scalars which require "
                    "reference/pointer tracking are not supported");
            Py_DECREF(*op);
            Py_DECREF(*op_dtype);
            return 0;
        }
    }
    else {
        PyErr_SetString(PyExc_ValueError,
                "Iterator input must be an array or a scalar");
        Py_DECREF(*op);
        return 0;
    }

    /* 'ndim' is the maximum of all the 'op_ndim' */
    if (*op_ndim > *ndim) {
        *ndim = *op_ndim;
    }

    return 1;
}

/*
 * Checks that the operand satisfies the READONLY/WRITEONLY properties
 * specified in 'flags'.
 *
 * Returns 1 on success, 0 on failure.
 */
static int
npyiter_check_flags_readwrite(PyObject* op, PyArray_Descr* op_dtype,
                              int op_type, npy_uint32 flags)
{
    if ((flags&NPY_ITER_GLOBAL_FLAGS) != 0) {
        PyErr_SetString(PyExc_ValueError,
                    "A global flag was passed as a per-operand flag "
                    "to the iterator constructor");
        return 0;
    }

    /* Error check the read/write flags */
    if (flags&NPY_ITER_READONLY) {
        /* The read/write flags are mutually exclusive */
        if (flags&(NPY_ITER_READWRITE|NPY_ITER_WRITEONLY)) {
            PyErr_SetString(PyExc_ValueError,
                    "Only one of the iterator flags NPY_ITER_READWRITE, "
                    "NPY_ITER_READONLY, and NPY_ITER_WRITEONLY may be "
                    "specified for an operand");
            return 0;
        }
        /* NULL operands must be write-only */
        if (op_type == NPY_ITER_OP_NULL) {
            PyErr_SetString(PyExc_ValueError,
                    "Automatic allocation was requested for an iterator "
                    "operand, but was set to NPY_ITER_READONLY instead of "
                    "NPY_ITER_WRITEONLY");
            return 0;
        }
    }
    else {
        /* The read/write flags are mutually exclusive */
        if ((flags&(NPY_ITER_READWRITE|NPY_ITER_WRITEONLY)) ==
                     (NPY_ITER_READWRITE|NPY_ITER_WRITEONLY)) {
            PyErr_SetString(PyExc_ValueError,
                    "Only one of the iterator flags NPY_ITER_READWRITE, "
                    "NPY_ITER_READONLY, and NPY_ITER_WRITEONLY may be "
                    "specified for an operand");
            return 0;
        }
        /* Must specify a read/write flag */
        if (!(flags&(NPY_ITER_READWRITE|NPY_ITER_WRITEONLY))) {
            PyErr_SetString(PyExc_ValueError,
                    "None of the iterator flags NPY_ITER_READWRITE, "
                    "NPY_ITER_READONLY, or NPY_ITER_WRITEONLY were "
                    "specified for an operand");
            return 0;
        }
        /* NULL operands must be write-only */
        if (op_type == NPY_ITER_OP_NULL &&
                    !(flags&NPY_ITER_WRITEONLY)) {
            PyErr_SetString(PyExc_ValueError,
                    "Automatic allocation was requested for an iterator "
                    "operand, but was set to NPY_ITER_READWRITE instead of "
                    "NPY_ITER_WRITEONLY");
            return 0;
        }
        
        /* Since write was specified, make sure the array is writeable */
        if (op_type == NPY_ITER_OP_ARRAY_SCALAR) {
            PyErr_SetString(PyExc_ValueError,
                    "Tried to construct an iterator for a "
                    "scalar without specifying the "
                    "NPY_ITER_READONLY flag.");
            return 0;
        }
        else if ((op_type == NPY_ITER_OP_ARRAY) &&
                            !PyArray_CHKFLAGS(op, NPY_WRITEABLE)) {
            PyErr_SetString(PyExc_ValueError,
                    "Tried to construct an iterator for a non-writeable "
                    "array without specifying the NPY_ITER_READONLY flag.");
            return 0;
        }
        /*
         * Also make sure that if the data type has a Python reference or
         * other pointer, ALLOW_WRITEABLE_REFERENCES was specified.
         */
        if (!(flags&NPY_ITER_ALLOW_WRITEABLE_REFERENCES)) {
            if (PyDataType_FLAGCHK(op_dtype, NPY_ITEM_HASOBJECT) ||
                        PyDataType_FLAGCHK(op_dtype, NPY_ITEM_IS_POINTER)) {
                PyErr_SetString(PyExc_ValueError,
                        "Tried to construct an iterator for a writeable "
                        "array of references/pointers without specifying the "
                        "NPY_ITER_ALLOW_WRITEABLE_REFERENCES flag.");
                return 0;
            }
        }
    }

    return 1;
}

/*
 * Fills in the AXISDATA for the 'niter' operands, broadcasting
 * the dimensionas as necessary.  Also fills
 * in the ITERSIZE data member.
 *
 * If op_axes is not NULL, it should point to an array of ndim-sized
 * arrays, one for each op.
 *
 * Return 1 on success, 0 on failure.
 */
static int
npyiter_fill_axisdata(PyArray_NpyIter *iter, PyObject **op,
                      npy_intp *op_ndim, char **op_dataptr,
                      npy_intp **op_axes)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp iiter, niter = NIT_NITER(iter);

    npy_intp ondim;
    char *odataptr, *axisdata0, *axisdata;
    npy_intp sizeof_axisdata;

    axisdata0 = NIT_AXISDATA(iter);
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);

    /* Process the first operand */
    if (op_axes == NULL || op_axes[0] == NULL) {
        /* Default broadcasting rules if op_axes is not specified */
        axisdata = axisdata0;
        ondim = op_ndim[0];
        odataptr = op_dataptr[0];
        /* Possible if op_axes are being used, but op_axes[0] is NULL */
        if (ondim > ndim) {
            PyErr_SetString(PyExc_ValueError,
                    "Iterator input has more dimensions than allowed "
                    "by the 'op_axes' specified");
            return 0;
        }
        for (idim = 0; idim < ondim; ++idim) {
            npy_intp shape = PyArray_DIM(op[0], ondim-idim-1);

            NAD_SHAPE(axisdata) = shape;
            NAD_COORD(axisdata) = 0;
            if (shape == 1) {
                NAD_STRIDES(axisdata)[0] = 0;
            }
            else {
                NAD_STRIDES(axisdata)[0] = PyArray_STRIDE(op[0], ondim-idim-1);
            }
            NAD_PTRS(axisdata)[0] = odataptr;

            axisdata += sizeof_axisdata;
        }
        for (idim = ondim; idim < ndim; ++idim) {
            NAD_SHAPE(axisdata) = 1;
            NAD_COORD(axisdata) = 0;
            NAD_STRIDES(axisdata)[0] = 0;
            NAD_PTRS(axisdata)[0] = odataptr;

            axisdata += sizeof_axisdata;
        }
    }
    else {
        npy_intp *axes = op_axes[0];

        /* Use op_axes to choose the axes */
        axisdata = axisdata0;
        ondim = op_ndim[0];
        odataptr = op_dataptr[0];
        for (idim = 0; idim < ndim; ++idim) {
            npy_intp i = axes[ndim-idim-1];
            if (i < 0) {
                NAD_SHAPE(axisdata) = 1;
                NAD_COORD(axisdata) = 0;
                NAD_STRIDES(axisdata)[0] = 0;
                NAD_PTRS(axisdata)[0] = odataptr;
            }
            else if (i < ondim) {
                npy_intp shape = PyArray_DIM(op[0], i);

                NAD_SHAPE(axisdata) = shape;
                NAD_COORD(axisdata) = 0;
                if (shape == 1) {
                    NAD_STRIDES(axisdata)[0] = 0;
                }
                else {
                    NAD_STRIDES(axisdata)[0] = PyArray_STRIDE(op[0], i);
                }
                NAD_PTRS(axisdata)[0] = odataptr;
            }
            else {
                PyErr_Format(PyExc_ValueError,
                        "Iterator input op_axes[0][%d] (==%d) is not a valid "
                        "axis of op[0], which has %d dimensions",
                        (int)(ndim-idim-1), (int)i, (int)ondim);
                return 0;
            }

            axisdata += sizeof_axisdata;
        }
    }

    /*
     * Process the rest of the operands, using the broadcasting rules
     * to combine them.
     */
    for (iiter = 1; iiter < niter; ++iiter) {
        if (op_axes == NULL || op_axes[iiter] == NULL) {
            axisdata = axisdata0;
            ondim = op_ndim[iiter];
            odataptr = op_dataptr[iiter];
            /* Possible if op_axes are being used, but op_axes[iiter] is NULL */
            if (ondim > ndim) {
                PyErr_SetString(PyExc_ValueError,
                        "Iterator input has more dimensions than allowed "
                        "by the 'op_axes' specified");
                return 0;
            }
            for (idim = 0; idim < ondim; ++idim) {
                npy_intp shape = PyArray_DIM(op[iiter], ondim-idim-1);

                if (shape == 1) {
                    NAD_STRIDES(axisdata)[iiter] = 0;
                }
                else {
                    if (NAD_SHAPE(axisdata) == 1) {
                        NAD_SHAPE(axisdata) = shape;
                    }
                    else if (NAD_SHAPE(axisdata) != shape) {
                        PyErr_SetString(PyExc_ValueError,
                                "Iterator input objects cannot be broadcast "
                                "to a single shape");
                        return 0;
                    }
                    NAD_STRIDES(axisdata)[iiter] = PyArray_STRIDE(
                                                      op[iiter], ondim-idim-1);
                }
                NAD_PTRS(axisdata)[iiter] = odataptr;

                axisdata += sizeof_axisdata;
            }
            for (idim = ondim; idim < ndim; ++idim) {
                NAD_STRIDES(axisdata)[iiter] = 0;
                NAD_PTRS(axisdata)[iiter] = odataptr;

                axisdata += sizeof_axisdata;
            }
        }
        else {
            npy_intp *axes = op_axes[iiter];

            /* Use op_axes to choose the axes */
            axisdata = axisdata0;
            ondim = op_ndim[iiter];
            odataptr = op_dataptr[iiter];
            for (idim = 0; idim < ndim; ++idim) {
                npy_intp i = axes[ndim-idim-1];
                if (i < 0) {
                    NAD_STRIDES(axisdata)[iiter] = 0;
                    NAD_PTRS(axisdata)[iiter] = odataptr;
                }
                else if (i < ondim) {
                    npy_intp shape = PyArray_DIM(op[iiter], i);

                    if (shape == 1) {
                        NAD_STRIDES(axisdata)[iiter] = 0;
                    }
                    else {
                        if (NAD_SHAPE(axisdata) == 1) {
                            NAD_SHAPE(axisdata) = shape;
                        }
                        else if (NAD_SHAPE(axisdata) != shape) {
                            PyErr_SetString(PyExc_ValueError,
                                    "Iterator input objects cannot be "
                                    "broadcast to a single shape");
                            return 0;
                        }
                        NAD_STRIDES(axisdata)[iiter] =
                                                PyArray_STRIDE(op[iiter], i);
                    }
                    NAD_PTRS(axisdata)[iiter] = odataptr;
                }
                else {
                    PyErr_Format(PyExc_ValueError,
                            "Iterator input op_axes[%d][%d] (==%d) is not a "
                            "valid axis of op[%d], which has %d dimensions ",
                            (int)iiter, (int)(ndim-idim-1), (int)i,
                            (int)iiter, (int)ondim);
                    return 0;
                }

                axisdata += sizeof_axisdata;
            }
        }
    }

    /* Now fill in the ITERSIZE member */
    NIT_ITERSIZE(iter) = 1;
    axisdata = axisdata0;
    for (idim = 0; idim < ndim; ++idim) {
        NIT_ITERSIZE(iter) *= NAD_SHAPE(axisdata);

        axisdata += sizeof_axisdata;
    }

    return 1;
}

/*
 * Computes the iterator's index strides and initializes the index values
 * to zero.
 *
 * This must be called before the axes (i.e. the AXISDATA array) may
 * be reordered.
 */
static void
npyiter_compute_index_strides(PyArray_NpyIter *iter, npy_uint32 flags)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    npy_intp indexstride;
    char* axisdata;
    npy_intp sizeof_axisdata;

    /*
     * If there is only one element being iterated, we just have
     * to touch the first AXISDATA because nothing will ever be
     * incremented.
     */
    if (NIT_ITERSIZE(iter) == 1) {
        if (itflags&NPY_ITER_FLAGS_HASINDEX) {
            axisdata = NIT_AXISDATA(iter);

            NAD_STRIDES(axisdata)[niter] = 0;
            NAD_PTRS(axisdata)[niter] = 0;
        }
        return;
    }

    if (flags&NPY_ITER_C_ORDER_INDEX) {
        sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
        axisdata = NIT_AXISDATA(iter);
        indexstride = 1;
        for(idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
            npy_intp shape = NAD_SHAPE(axisdata);

            if (shape == 1) {
                NAD_STRIDES(axisdata)[niter] = 0;
            }
            else {
                NAD_STRIDES(axisdata)[niter] = indexstride;
            }
            NAD_PTRS(axisdata)[niter] = 0;
            indexstride *= shape;
        }
    }
    else if (flags&NPY_ITER_F_ORDER_INDEX) {
        sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
        axisdata = NIT_AXISDATA(iter) + (ndim-1)*sizeof_axisdata;
        indexstride = 1;
        for(idim = 0; idim < ndim; ++idim, axisdata -= sizeof_axisdata) {
            npy_intp shape = NAD_SHAPE(axisdata);

            if (shape == 1) {
                NAD_STRIDES(axisdata)[niter] = 0;
            }
            else {
                NAD_STRIDES(axisdata)[niter] = indexstride;
            }
            NAD_PTRS(axisdata)[niter] = 0;
            indexstride *= shape;
        }
    }
}

/*
 * If the flags specify a forced iteration order, applies it
 * to the iterator, and indicates in its itflags that the iteration
 * order was forced.
 */
static void
npyiter_apply_forced_iteration_order(npy_uint32 flags, PyArray_NpyIter *iter)
{
    /*npy_uint32 itflags = NIT_ITFLAGS(iter);*/
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp iiter, niter = NIT_NITER(iter);

    if (flags&NPY_ITER_FORCE_C_ORDER) {
        NIT_ITFLAGS(iter) |= NPY_ITER_FLAGS_FORCEDORDER;
    }
    else if (flags&NPY_ITER_FORCE_F_ORDER) {
        npyiter_reverse_axis_ordering(iter);
        NIT_ITFLAGS(iter) |= NPY_ITER_FLAGS_FORCEDORDER;
    }
    else if(flags&NPY_ITER_FORCE_ANY_CONTIGUOUS) {
        PyObject **op = NIT_OBJECTS(iter);
        int forder = 1;

        /* Check that all the array inputs are fortran order */
        for (iiter = 0; iiter < niter; ++iiter, ++op) {
            if (PyArray_Check(*op) &&
                    !PyArray_CHKFLAGS(*op, NPY_F_CONTIGUOUS)) {
               forder = 0;
               break;
            }
        }

        if (forder) {
            npyiter_reverse_axis_ordering(iter);
        }
        NIT_ITFLAGS(iter) |= NPY_ITER_FLAGS_FORCEDORDER;
    }
}


/*
 * This function negates any strides in the iterator
 * which are negative.  When iterating more than one
 * object, it only flips strides when they are all
 * negative or zero.
 */
static void
npyiter_flip_negative_strides(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp iiter, niter = NIT_NITER(iter);

    npy_intp istrides, nstrides = NAD_NSTRIDES();
    char *axisdata, *axisdata0;
    npy_intp *ptrs0;
    npy_intp sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
    int any_flipped = 0;

    axisdata0 = axisdata = NIT_AXISDATA(iter);
    ptrs0 = (npy_intp*)NAD_PTRS(axisdata0);
    for (idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
        npy_intp *strides = NAD_STRIDES(axisdata);
        int any_negative = 0;

        /*
         * Check the signs of all the strides, excluding
         * the index stride at the end.
         */
        for (iiter = 0; iiter < niter; ++iiter) {
            if (strides[iiter] < 0) {
                any_negative = 1;
            }
            else if (strides[iiter] != 0) {
                break;
            }
        }
        /*
         * If at least on stride is negative and none are positive,
         * flip all the strides for this dimension.
         */
        if (any_negative && iiter == niter) {
            npy_intp shapem1 = NAD_SHAPE(axisdata) - 1;

            for (istrides = 0; istrides < nstrides; ++istrides) {
                npy_intp stride = strides[istrides];

                /* Adjust the base pointers to start at the end */
                ptrs0[istrides] += shapem1 * stride;
                /* Flip the stride */
                strides[istrides] = -stride;
            }
            /* Make the perm entry negative, so getcoords knows it's  flipped */
            NIT_PERM(iter)[idim] = -1-NIT_PERM(iter)[idim];

            any_flipped = 1;
        }
    }

    /*
     * If any strides were flipped, the base pointers were adjusted
     * in the first AXISDATA, and need to be copied to all the rest
     */
    if (any_flipped) {
        npy_intp *resetdataptr = (npy_intp*)NIT_RESETDATAPTR(iter);

        for (istrides = 0; istrides < nstrides; ++istrides) {
            resetdataptr[istrides] = ptrs0[istrides];
        }
        axisdata = axisdata0;
        for (idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
            npy_intp *ptrs = (npy_intp*)NAD_PTRS(axisdata);
            for (istrides = 0; istrides < nstrides; ++istrides) {
                ptrs[istrides] = ptrs0[istrides];
            }
        }
        /*
         * Indicate that some of the perm entries are negative,
         * and that it's not (strictly speaking) the identity perm.
         */
        NIT_ITFLAGS(iter) = (NIT_ITFLAGS(iter)|NPY_ITER_FLAGS_NEGPERM) &
                            ~NPY_ITER_FLAGS_IDENTPERM;
    }
}

static void
npyiter_reverse_axis_ordering(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    npy_intp i, temp, size;
    npy_intp* first;
    npy_intp* last;

    /* Need at least two dimensions for reversing to change things */
    if (ndim < 2) {
        return;
    }

    size = NIT_SIZEOF_AXISDATA(itflags, ndim, niter)/NPY_SIZEOF_INTP;
    first = (npy_intp*)NIT_AXISDATA(iter);
    last = first + (ndim-1)*size;

    /* This loop reverses the order of the AXISDATA array */
    while (first < last) {
        for (i = 0; i < size; ++i) {
            temp = first[i];
            first[i] = last[i];
            last[i] = temp;
        }
        first += size;
        last -= size;
    }

    /* Store the perm we applied */
    first = NIT_PERM(iter);
    for(i = ndim-1; i >= 0; --i, ++first) {
        *first = i;
    }

    NIT_ITFLAGS(iter) &= ~NPY_ITER_FLAGS_IDENTPERM;
}

static npy_intp intp_abs(npy_intp x)
{
    return (x < 0) ? -x : x;
}

static void 
npyiter_find_best_axis_ordering(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp iiter, niter = NIT_NITER(iter);

    npy_intp i0, i1, ipos, j0, j1;
    npy_intp *perm;
    char *axisdata = NIT_AXISDATA(iter);
    npy_intp sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
    int permuted = 0;

    perm = NIT_PERM(iter);
    
    /*
     * Do a custom stable insertion sort.  Note that because
     * the AXISDATA has been reversed from C order, this
     * is sorting from smallest stride to biggest stride.
     */
    for (i0 = 1; i0 < ndim; ++i0) {
        npy_intp *strides0;

        /* 'ipos' is where perm[i0] will get inserted */
        ipos = i0;
        j0 = perm[i0];
        strides0 = NAD_STRIDES(axisdata + j0*sizeof_axisdata);
        for (i1 = i0-1; i1 >= 0; --i1) {
            int ambig = 1, shouldswap = 0;
            npy_intp *strides1;

            j1 = perm[i1];
            strides1 = NAD_STRIDES(axisdata + j1*sizeof_axisdata);

            for (iiter = 0; iiter < niter; ++iiter) {
                if (strides0[iiter] != 0 && strides1[iiter] != 0) {
                    if (intp_abs(strides1[iiter]) <=
                                            intp_abs(strides0[iiter])) {
                        /*
                         * Set swap even if it's not ambiguous already,
                         * because in the case of conflicts between
                         * different operands, C-order wins.
                         */
                        shouldswap = 0;
                    }
                    else {
                        /* Only set swap if it's still ambiguous */
                        if (ambig) {
                            shouldswap = 1;
                        }
                    }
                    
                    /*
                     * A comparison has been done, so it's
                     * no longer ambiguous
                     */
                    ambig = 0;
                }
            }
            /*
             * If the comparison was unambiguous, either shift
             * 'ipos' to 'i1' or stop looking for an insertion
             * point
             */
            if (!ambig) {
                if (shouldswap) {
                    ipos = i1;
                }
                else {
                    break;
                }
            }
        }

        /* Insert perm[i0] into the right place */
        if (ipos != i0) {
            for (i1 = i0; i1 > ipos; --i1) {
                perm[i1] = perm[i1-1];
            }
            perm[ipos] = j0;
            permuted = 1;
        }
    }

    /* Apply the computed permutation to the AXISDATA array */
    if (permuted == 1) {
        npy_intp i, size = sizeof_axisdata/NPY_SIZEOF_INTP;
        char *ad_i;

        /* Use the coord as a flag, set each to 1 */
        for (idim = 0; idim < ndim; ++idim) {
            NAD_COORD(axisdata + idim*sizeof_axisdata) = 1;
        }
        /* Apply the permutation by following the cycles */
        for (idim = 0; idim < ndim; ++idim) {
            ad_i = axisdata + idim*sizeof_axisdata;

            /* If this axis hasn't been touched yet, process it */
            if (NAD_COORD(ad_i) == 1) {
                npy_intp pidim = perm[idim], qidim, tmp;
                char *ad_p, *ad_q;

                if (pidim != idim) {
                    /* Follow the cycle, copying the data */
                    for (i = 0; i < size; ++i) {
                        qidim = idim;
                        pidim = perm[idim];
                        ad_q = ad_i;
                        tmp = *((npy_intp*)ad_q + i);
                        while (pidim != idim) {
                            ad_p = axisdata + pidim*sizeof_axisdata;
                            *((npy_intp*)ad_q + i) = *((npy_intp*)ad_p + i);

                            qidim = pidim;
                            ad_q = ad_p;
                            pidim = perm[pidim];
                        }
                        *((npy_intp*)ad_q + i) = tmp;
                    }
                    /* Follow the cycle again, marking it as done */
                    pidim = perm[idim];
                    while (pidim != idim) {
                        NAD_COORD(axisdata + pidim*sizeof_axisdata) = 0;
                        pidim = perm[pidim];
                    }
                }
                NAD_COORD(ad_i) = 0;
            }
        }
        /* Clear the identity perm flag */
        NIT_ITFLAGS(iter) &= ~NPY_ITER_FLAGS_IDENTPERM;
    }
}

static void 
npyiter_coalesce_axes(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    npy_intp istrides, nstrides = NAD_NSTRIDES();
    char *axisdata = NIT_AXISDATA(iter);
    npy_intp sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
    char *ad_compress;
    npy_intp new_ndim = 1;

    /* The HASCOORDS or IDENTPERM flags do not apply after coalescing */
    NIT_ITFLAGS(iter) &= ~(NPY_ITER_FLAGS_IDENTPERM|NPY_ITER_FLAGS_HASCOORDS);

    axisdata = NIT_AXISDATA(iter);
    ad_compress = axisdata;

    for (idim = 0; idim < ndim-1; ++idim) {
        int can_coalesce = 1;
        npy_intp shape0 = NAD_SHAPE(ad_compress);
        npy_intp shape1 = NAD_SHAPE(axisdata + sizeof_axisdata);
        npy_intp *strides0 = NAD_STRIDES(ad_compress);
        npy_intp *strides1 = NAD_STRIDES(axisdata + sizeof_axisdata);

        /* Check that all the axes can be coalesced */
        for (istrides = 0; istrides < nstrides; ++istrides) {
            if (!((shape0 == 1 && strides0[istrides] == 0) ||
                  (shape1 == 1 && strides1[istrides] == 0)) &&
                     (strides0[istrides]*shape0 != strides1[istrides])) {
                can_coalesce = 0;
                break;
            }
        }

        if (can_coalesce) {
            npy_intp *strides = NAD_STRIDES(ad_compress);

            axisdata += sizeof_axisdata;
            NAD_SHAPE(ad_compress) *= NAD_SHAPE(axisdata);
            for (istrides = 0; istrides < nstrides; ++istrides) {
                if (strides[istrides] == 0) {
                    strides[istrides] = NAD_STRIDES(axisdata)[istrides];
                }
            }
        }
        else {
            axisdata += sizeof_axisdata;
            ad_compress += sizeof_axisdata;
            if (ad_compress != axisdata) {
                memcpy(ad_compress, axisdata, sizeof_axisdata);
            }
            ++new_ndim;
        }
    }

    /*
     * If the number of axes shrunk, reset the perm and
     * compress the data into the new layout.
     */
    if (new_ndim < ndim) {
        npy_intp *perm = NIT_PERM(iter);

        /* Reset to an identity perm */
        for (idim = 0; idim < new_ndim; ++idim) {
            perm[idim] = idim;
        }
        npyiter_shrink_ndim(iter, new_ndim);
    }
}

static void
npyiter_shrink_ndim(PyArray_NpyIter *iter, npy_intp new_ndim)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp ndim = NIT_NDIM(iter);
    npy_intp niter = NIT_NITER(iter);

    char *iterdata = (char*)iter;

    /*
     * The only place that will shift is perm[ndim], so only one
     * memmove is needed for the data after that.  Also, any
     * extra buffers stored after the main iterator structure shouldn't
     * be moved.
     */
    memmove(iterdata + NIT_DTYPES_OFFSET(itflags, new_ndim, niter),
            iterdata + NIT_DTYPES_OFFSET(itflags, ndim, niter),
            NIT_SIZEOF_ITERATOR(itflags, new_ndim, niter) -
            NIT_DTYPES_OFFSET(itflags, new_ndim, niter));
    
    NIT_NDIM(iter) = new_ndim;
}

/* For debugging */
NPY_NO_EXPORT void
NpyIter_DebugPrint(PyArray_NpyIter *iter)
{
    npy_uint32 itflags = NIT_ITFLAGS(iter);
    npy_intp idim, ndim = NIT_NDIM(iter);
    npy_intp iiter, niter = NIT_NITER(iter);

    char *axisdata;
    npy_intp sizeof_axisdata;

    printf("\n------ BEGIN ITERATOR DUMP ------\n");
    printf("Flags: ");
    if (itflags&NPY_ITER_FLAGS_IDENTPERM)
        printf("IDENTPERM ");
    if (itflags&NPY_ITER_FLAGS_NEGPERM)
        printf("NEGPERM ");
    if (itflags&NPY_ITER_FLAGS_HASINDEX)
        printf("HASINDEX ");
    if (itflags&NPY_ITER_FLAGS_HASCOORDS)
        printf("HASCOORDS ");
    if (itflags&NPY_ITER_FLAGS_FORCEDORDER)
        printf("FORCEDORDER ");
    if (itflags&NPY_ITER_FLAGS_NOINNER)
        printf("NOINNER ");
    printf("\n");
    printf("NDim: %d\n", (int)ndim);
    printf("NIter: %d\n", (int)niter);
    printf("IterSize: %d\n", (int)NIT_ITERSIZE(iter));
    printf("Iterator SizeOf: %d\n",
                            (int)NIT_SIZEOF_ITERATOR(itflags, ndim, niter));
    printf("AxisData SizeOf: %d\n",
                            (int)NIT_SIZEOF_AXISDATA(itflags, ndim, niter));
    printf("\n");

    printf("Perm: ");
    for (idim = 0; idim < ndim; ++idim) {
        printf("%d ", (int)NIT_PERM(iter)[idim]);
    }
    printf("\n");
    printf("DTypes: ");
    for (iiter = 0; iiter < niter; ++iiter) {
        printf("%p ", NIT_DTYPES(iter)[iiter]);
    }
    printf("\n");
    printf("DTypes: ");
    for (iiter = 0; iiter < niter; ++iiter) {
        PyObject_Print((PyObject*)NIT_DTYPES(iter)[iiter], stdout, 0);
        printf(" "); 
    }
    printf("\n");
    printf("ItemSizes: ");
    for (iiter = 0; iiter < niter; ++iiter) {
        printf("%d ", (int)NIT_ITEMSIZES(iter)[iiter]);
    }
    printf("\n");
    printf("InitDataPtrs: ");
    for (iiter = 0; iiter < niter; ++iiter) {
        printf("%p ", NIT_RESETDATAPTR(iter)[iiter]);
    }
    printf("\n");
    if (itflags&NPY_ITER_FLAGS_HASINDEX) {
        printf("InitIndex: %d\n",
                        (int)(npy_intp)NIT_RESETDATAPTR(iter)[niter]);
    }
    printf("Objects: ");
    for (iiter = 0; iiter < niter; ++iiter) {
        printf("%p ", NIT_OBJECTS(iter)[iiter]);
    }
    printf("\n");
    printf("\n");

    axisdata = NIT_AXISDATA(iter);
    sizeof_axisdata = NIT_SIZEOF_AXISDATA(itflags, ndim, niter);
    for (idim = 0; idim < ndim; ++idim, axisdata += sizeof_axisdata) {
        printf("AxisData[%d]:\n", (int)idim);
        printf("  Shape: %d\n", (int)NAD_SHAPE(axisdata));
        printf("  Coord: %d\n", (int)NAD_COORD(axisdata));
        printf("  Strides: ");
        for (iiter = 0; iiter < niter; ++iiter) {
            printf("%d ", (int)NAD_STRIDES(axisdata)[iiter]);
        }
        printf("\n");
        if (itflags&NPY_ITER_FLAGS_HASINDEX) {
            printf("  Index Stride: %d\n", (int)NAD_STRIDES(axisdata)[niter]);
        }
        printf("  Ptrs: ");
        for (iiter = 0; iiter < niter; ++iiter) {
            printf("%p ", NAD_PTRS(axisdata)[iiter]);
        }
        printf("\n");
        if (itflags&NPY_ITER_FLAGS_HASINDEX) {
            printf("  Index Value: %d\n",
                               (int)((npy_intp*)NAD_PTRS(axisdata))[niter]);
        }
    }

    printf("------- END ITERATOR DUMP -------\n");
}

